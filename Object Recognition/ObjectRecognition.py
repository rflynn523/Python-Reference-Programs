# Ryan Flynn
# Robotic Systems Project 2
# Takes in a set of images and uses two different techniques (Template Matching and
# Color Histogram) to try and recognize ach image with the entire set of twenty images.

# For each query, prints out the class it belongs to, the query number, the template mathcing
# score, the color histogram score, the top 4 template matching queries and the top 4
# color histogram queries.

# -*- coding: utf-8 -*-
"""Computer Vision Project: Object Recognition.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1b5sv-QI4u7AjUlwScwRBuQu5PIBcHLps

Author: Ryan Flynn      <br/>
Python: 2.7.15+         <br/>
OpenCV: 3.4.3
"""

import cv2
import sys
print("OpenCV: ", cv2.__version__)
print("Python: ", sys.version)

# Here, we import the required libraries
import glob
from operator import itemgetter
import numpy as np
import cv2
from google.colab.patches import cv2_imshow

# Load the Drive helper and mount
from google.colab import drive

# This will prompt for authorization.
drive.mount('/content/drive/')

# After executing the cell above, Store the images directory with the images
# inside it in your notebook. Check the images with the below command
!ls "/content/drive/My Drive/Colab Notebooks/images"

# Get all images
images = glob.glob("/content/drive/My Drive/Colab Notebooks/images/*.jpg")

# Create a class with the functions which are required to hold the processes that
# need to be applied on the images.
class object_recognition():

    ''' Note: If query_img = None, take the path to dataset by deault,
        else process single image.'''


    def matching(self, meth, query_input=None):

        final_matches_list = []
        if query_input is not None:
            queue_label = query
            queue_img = query_images_list
        else:
            queue_label = images
            queue_img = template_images_list


        for i, inst in enumerate(queue_label):
            #Get the name of the image file without extension
            inst_match = {"query":inst.partition('/')[2].strip("/content/drive/My Drive/Colab Notebooks/images_2/images/ukbench").split('.')[0]}

            all_matches_list =[]
            for j, tmp in enumerate(images):

                # Apply template matching
                analyze_color = cv2.imread(images[i])
                template_color = cv2.imread(images[j])

                analyze = cv2.cvtColor(analyze_color, cv2.COLOR_BGR2GRAY)
                template = cv2.cvtColor(template_color, cv2.COLOR_BGR2GRAY)

                res = cv2.matchTemplate(analyze, template, meth)
                min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(res)

                # Apply color histogram
                analyze_hist = cv2.calcHist(analyze, [0], None, [256], [0, 256])
                template_hist = cv2.calcHist(template, [0], None, [256], [0, 256])

                color_histogram = cv2.compareHist(analyze_hist, template_hist, cv2.HISTCMP_CORREL)

                all_matches_list.append([tmp.partition('/')[2].strip("/content/drive/My Drive/Colab Notebooks/images_2/images/ukbench/ukbench").split('.')[0], max_val, color_histogram])


            inst_match["temp_matches"] = all_matches_list
            final_matches_list.append(inst_match)


        return final_matches_list



    def scoring(self, match_result_list):

        # Sort and split the queries into the five different classes
        match_result_list.sort()

        # split into the five classes
        # (duck(20-23), chair(284-287), person(720-723), frame(1492-1495), pictures(9120-9123))

        # Dictionary that maps the image to a list that conatins
        # it's cass, top four template matching images, template matching score,
        # top four color matching images and the color matching score.
        top_4 = {}

        # Loops through the keys
        # n is the index in the list, m is the list of scores
        for n, m in enumerate(match_result_list):
          # Looks at the query keys
          # Classifies the five different picture groups

          if n < 4:
            clss = "duck"

          elif n < 8:
            clss = "chair"

          elif n < 12:
            clss = "person"

          elif n < 16:
            clss = "frame"

          elif n < 20:
            clss = "pictures"

          res = m.get("temp_matches")

          # Get the top four template matching images
          res.sort(key=sortTM, reverse=True)
          four = res[:4]

          TM = []
          for f in four:
            TM.append(f[0])

          # Get the top four of color histogram images
          res.sort(key=sortCH, reverse=True)
          four = res[:4]

          CH = []
          for f in four:
            CH.append(f[0])

          # Score the template mathcing and color histogram results
          TM_score = getScore(clss, TM)
          CH_score = getScore(clss, CH)

          # Add everything into the dictionary.
          top_4[m.get("query")] = [clss, TM, TM_score, CH, CH_score]

        return top_4

    def eval_cal(self, scoring_result):
        # remove pass after putting your code in the function

        sum_TM = 0
        sum_CH = 0

        for s in scoring_result:
          results = s.get("temp_matches")

          for r in results:
            sum_TM += r[1]
            sum_CH += r[2]

        mean_TM = sum_TM / 20
        mean_CH = sum_CH / 10


        return [["Template_match_mean", mean_TM], ["color_histogram_mean",mean_CH]]

def sortTM(elem):
  return elem[1]

def sortCH(elem):
  return elem[2]

# Helper function that scores the passed in list (pics) based on the passed in class (c).
def getScore(c, pics):
  score = 0

  if(c == "duck"):
    minVal = 20
    maxVal = 23

  elif(c == "chair"):
    minVal = 284
    maxVal = 287

  elif(c == "person"):
    minVal = 720
    maxVal = 723

  elif(c == "frame"):
    minVal = 1492
    maxVal = 1495

  elif(c == "pictures"):
    minVal = 9120
    maxVal = 9123

  # Looks for the images that fall with in the class' range
  for p in pics:
    if (int(p) <= maxVal and int(p) >= minVal):
      score += 1

  return score

# Main run

  query_images_list = []
  template_images_list = []

  '''You can specify the image name in the query for testing. See example below'''
#   query = ['/content/drive/My Drive/Colab Notebooks/assignment_2/images/ukbench00020.jpg',
#         '/content/drive/My Drive/Colab Notebooks/assignment_2/images/ukbench00021.jpg',
#         '/content/drive/My Drive/Colab Notebooks/assignment_2/images/ukbench00022.jpg',
#         '/content/drive/My Drive/Colab Notebooks/assignment_2/images/ukbench00023.jpg']
  query = None

  try:
      obj_rec = object_recognition()

      '''Run on query_img if argument passed, otherwise run on dataset'''
      if query != None:

          for query_img in query:
              query_images_list.append(cv2.imread(query_img, 0))

      for i in range(len(images)):
          template_images_list.append(cv2.imread(images[i], 0))


      method = cv2.TM_CCOEFF_NORMED

      matching_results = obj_rec.matching(method, query)
      sorted_scored_top4 = obj_rec.scoring(matching_results)
      evaluation_results = obj_rec.eval_cal(matching_results)

      for n, (k, v) in enumerate(sorted_scored_top4.items()):

        print("class: " + v[0])
        print("query: "+ k)
        print("score_TM = " + str(v[2]))
        print("score_CH = " + str(v[4]))
        print("top_4_TM = " + str(v[1]))
        print("top_4_CH = " + str(v[3]))
        print

      print(evaluation_results)

  except KeyboardInterrupt:
    print("Shutting down")
